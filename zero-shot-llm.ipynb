{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":198459806,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers torch","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:40:25.113364Z","iopub.execute_input":"2024-08-23T02:40:25.114231Z","iopub.status.idle":"2024-08-23T02:43:27.571617Z","shell.execute_reply.started":"2024-08-23T02:40:25.114192Z","shell.execute_reply":"2024-08-23T02:43:27.570476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade bitsandbytes accelerate peft","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:43:27.573726Z","iopub.execute_input":"2024-08-23T02:43:27.574058Z","iopub.status.idle":"2024-08-23T02:43:47.973088Z","shell.execute_reply.started":"2024-08-23T02:43:27.574028Z","shell.execute_reply":"2024-08-23T02:43:47.972113Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom transformers import set_seed\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:43:47.974669Z","iopub.execute_input":"2024-08-23T02:43:47.975042Z","iopub.status.idle":"2024-08-23T02:43:52.244969Z","shell.execute_reply.started":"2024-08-23T02:43:47.975004Z","shell.execute_reply":"2024-08-23T02:43:52.244188Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset='dblp'\nnome_llm='llama3' # flan # bloomz # llama13b","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:43:52.253637Z","iopub.execute_input":"2024-08-23T02:43:52.254037Z","iopub.status.idle":"2024-08-23T02:43:52.382360Z","shell.execute_reply.started":"2024-08-23T02:43:52.253990Z","shell.execute_reply":"2024-08-23T02:43:52.381232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reprodutibilidade da solucao\nimport random, torch, numpy\nSEED=42\nrandom.seed(SEED); torch.manual_seed(SEED); numpy.random.seed(seed=SEED) # reproducibily soluction  \n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:43:52.383864Z","iopub.execute_input":"2024-08-23T02:43:52.384509Z","iopub.status.idle":"2024-08-23T02:43:52.395539Z","shell.execute_reply.started":"2024-08-23T02:43:52.384471Z","shell.execute_reply":"2024-08-23T02:43:52.394701Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if nome_llm == \"llama3\":\n    nome_modelo = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n    model = AutoModelForCausalLM.from_pretrained(nome_modelo, \n            token=TOKEN_USUARIO, torch_dtype=\"auto\", device_map=\"auto\", load_in_4bit=True\n    )\n    tokenizer = AutoTokenizer.from_pretrained(nome_modelo, token=TOKEN_USUARIO)\n\nelif nome_llm == 'flan':\n    model_name='google/flan-t5-xxl' # \"google/flan-t5-xl\"\n    tokenizer = T5Tokenizer.from_pretrained(model_name)\n    model = T5ForConditionalGeneration.from_pretrained(model_name)\n\ndef zero_shot(df, reference):\n    results = []\n    for i in range(len(df)):         \n        if i%10==0:\n            print(i)\n\n        prompt = f\"\"\"Classify the topic of the text exclusively among the references:\nInput: I bought new equipment to build my first robot.\nReference:\na. computer vision\nb. computational linguistics\nc. biomedical engineering\nd. software engineering\ne. graphics\nf. data mining\ng. security and cryptography\nh. signal processing\ni. robotics\nj. theory\nAnswer: i\nInput: {df.iloc[i]['text']}\nReference:\na. computer vision\nb. computational linguistics\nc. biomedical engineering\nd. software engineering\ne. graphics\nf. data mining\ng. security and cryptography\nh. signal processing\ni. robotics\nj. theory\nAnswer: \"\"\"\n\n        if nome_llm == 'llama' or nome_llm == 'llama13b':\n            inputs = tokenizer.encode(prompt, max_length=2048, return_tensors=\"pt\").to(\"cuda\")              \n            #inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")    \n        elif nome_llm == 'flan':\n            inputs = tokenizer.encode(prompt, max_length=512, return_tensors=\"pt\").to(\"cuda\")   \n        else:            \n            inputs = tokenizer.encode(prompt,  max_length=1024,  return_tensors=\"pt\").to(\"cuda\") \n        \n        set_seed(42)\n        outputs = model.generate(inputs, max_new_tokens=1)\n        \n        results.append(tokenizer.decode(outputs[0][len(inputs[0]):]))\n        \n    df[nome_modelo] = results","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T02:43:52.396871Z","iopub.execute_input":"2024-08-23T02:43:52.397278Z","iopub.status.idle":"2024-08-23T02:45:33.466714Z","shell.execute_reply.started":"2024-08-23T02:43:52.397222Z","shell.execute_reply":"2024-08-23T02:45:33.465797Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import timeit  # calcular metrica de tempo\n#import torch\n#with torch.autocast(\"cuda\"): \n\nini = timeit.default_timer()\ndf = pd.read_parquet(f\"/kaggle/input/datasets-sentiment/{dataset}.parquet\")\n\nimport string\nletters = string.ascii_lowercase\n# reference = \"Reference:\\n\"\n# name_classe = df['label'].unique()\n# for i_classe in range(len(name_classe)):\n#     reference += f\"{letters[i_classe]}. {name_classe[i_classe]}\\n\"\nreference=None  \n#df = df.iloc[0:20]\nfor i in range(100):    \n    print(f'parte:{i}')\n    df_temp = df.iloc[i*1000:(i+1)*1000]\n    zero_shot(df_temp, reference)\n    df_temp.to_parquet(f\"df_{dataset}_{nome_llm}_parte{i}.parquet\")    \n    if (i+1)*1000 > len(df):\n        break\nprint(timeit.default_timer() - ini)\ntempo_predicao = timeit.default_timer() - ini\n#df","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:45:33.467862Z","iopub.execute_input":"2024-08-23T02:45:33.468185Z","iopub.status.idle":"2024-08-23T02:47:05.912742Z","shell.execute_reply.started":"2024-08-23T02:45:33.468144Z","shell.execute_reply":"2024-08-23T02:47:05.910481Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ndef list_files(dir):\n    \"\"\"Return list of the files in directory. Example: list_files('Downloads'); Return=['a.txt', 'b.txt']\"\"\"\n    files_name =[]\n    for r, d, files_array in os.walk(dir):\n        for f in files_array:\n            if '.parquet' in f:\n                files_name.append(f)\n    return files_name","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:47:05.913776Z","iopub.status.idle":"2024-08-23T02:47:05.914163Z","shell.execute_reply.started":"2024-08-23T02:47:05.913973Z","shell.execute_reply":"2024-08-23T02:47:05.913990Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame()\nfor i in range( len(list_files(\"./\")) ):    \n    df = pd.concat([df, \n               pd.read_parquet(f'./df_{dataset}_{nome_llm}_parte{i}.parquet')\n              ])\ndf","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:47:05.915243Z","iopub.status.idle":"2024-08-23T02:47:05.915671Z","shell.execute_reply.started":"2024-08-23T02:47:05.915425Z","shell.execute_reply":"2024-08-23T02:47:05.915450Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = []\nfor i in range(len(df)):\n    if 'a' in df.iloc[i][nome_modelo]:\n        pred.append(0)\n    elif 'b' in df.iloc[i][nome_modelo]:\n        pred.append(1)\n    elif 'c' in df.iloc[i][nome_modelo]:\n        pred.append(2)    \n    elif 'c' in df.iloc[i][nome_modelo]:\n        pred.append(3)  \n    elif 'e' in df.iloc[i][nome_modelo]:\n        pred.append(4)  \n    elif 'f' in df.iloc[i][nome_modelo]:\n        pred.append(5)  \n    elif 'g' in df.iloc[i][nome_modelo]:\n        pred.append(6)  \n    elif 'h' in df.iloc[i][nome_modelo]:\n        pred.append(7)  \n    elif 'i' in df.iloc[i][nome_modelo]:\n        pred.append(8)\n    else:\n        pred.append(9) #theory , majoriataria        \ndf[nome_modelo +'_pred'] = pred\n ","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:47:05.917436Z","iopub.status.idle":"2024-08-23T02:47:05.917829Z","shell.execute_reply.started":"2024-08-23T02:47:05.917644Z","shell.execute_reply":"2024-08-23T02:47:05.917662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import collections\n\ncollections.Counter(df['meta-llama/Meta-Llama-3.1-8B-Instruct'])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:47:05.918944Z","iopub.status.idle":"2024-08-23T02:47:05.919340Z","shell.execute_reply.started":"2024-08-23T02:47:05.919117Z","shell.execute_reply":"2024-08-23T02:47:05.919134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nfor index_fold in range(5):\n    folds = pd.read_parquet(f'/kaggle/input/datasets-sentiment/{dataset}_folds.parquet')\n    test = df.iloc[folds.iloc[index_fold]['test_idxs']]\n    micro = f1_score(list(test['label']), list(test[nome_modelo +'_pred']), average='micro')\n    macro = f1_score(list(test['label']), list(test[nome_modelo +'_pred']), average='macro')\n    f1_classes = f1_score(list(test['label']), list(test[nome_modelo +'_pred']), average=None)\n\n    print(f\"{dataset}_{nome_modelo}\\t{index_fold}\\t{micro}\\t{macro}\\t{tempo_predicao}\\t{list(test[nome_modelo +'_pred'])}\")\n    #print(f\"{dataset}_{nome_modelo}\\t{index_fold}\\t{micro}\\t{macro}\\t\\t{f1_classes[0]}\\t{f1_classes[1]}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T02:47:05.920681Z","iopub.status.idle":"2024-08-23T02:47:05.921000Z","shell.execute_reply.started":"2024-08-23T02:47:05.920838Z","shell.execute_reply":"2024-08-23T02:47:05.920853Z"},"trusted":true},"outputs":[],"execution_count":null}]}